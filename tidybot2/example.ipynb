{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tidybot2.utils import get_policy, rmat_to_quat, rot6d_to_rmat, get_cfg\n",
    "from tidybot2.policy_wrapper import PolicyWrapper\n",
    "import numpy as np\n",
    "from actpp.actpp_policy import ACTPolicy\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_pw_cfg = {\n",
    "    \"n_obs\": 2,\n",
    "    \"n_acts\": 8,\n",
    "    \"d_pos\": 6,\n",
    "    \"d_rot\": 6\n",
    "}\n",
    "\n",
    "actpp_pw_cfg = {\n",
    "    \"n_obs\": 1,\n",
    "    \"n_acts\": 8,\n",
    "    \"d_pos\": 6,\n",
    "    \"d_rot\": 6\n",
    "}\n",
    "\n",
    "def test_policy(policy, dummy_normalizer, pw_cfg):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    policy = policy.to(device)\n",
    "    policy.eval()\n",
    "    for param in policy.parameters():\n",
    "        param.requires_grad = False\n",
    "    if dummy_normalizer:\n",
    "        policy.set_normalizer(None, dummy_normalizer)\n",
    "    pw = PolicyWrapper(policy, device=device, **pw_cfg)\n",
    "\n",
    "    # This is for the mobile base, fill in with your shapes\n",
    "    obs = {\n",
    "        'base_pose': np.zeros(3, dtype=np.float32),\n",
    "        'arm_pos': np.zeros(3, dtype=np.float32),\n",
    "        'arm_rot': np.zeros(6, dtype=np.float32),\n",
    "        'arm_rot_wrt_start': np.zeros(6, dtype=np.float32),\n",
    "        'gripper_pos': np.zeros(1, dtype=np.float32),\n",
    "        'base_image': np.zeros((84, 84, 3), dtype=np.uint8),\n",
    "        'wrist_image': np.zeros((84, 84, 3), dtype=np.uint8),\n",
    "    }\n",
    "\n",
    "    action = pw.get_action(obs)\n",
    "    print(action)\n",
    "\n",
    "    base_pose = action[:3]\n",
    "    arm_pos = action[3:6]\n",
    "    arm_6d = torch.from_numpy(action[6:12])\n",
    "    arm_quat = rmat_to_quat(rot6d_to_rmat(arm_6d))\n",
    "    gripper_pos = action[12:13]\n",
    "\n",
    "    action_dict = {\n",
    "        'base_pose': base_pose,\n",
    "        'arm_pos': arm_pos,\n",
    "        'arm_quat': arm_quat,\n",
    "        'gripper_pos': gripper_pos\n",
    "    }\n",
    "\n",
    "    return action_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion Policy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = '/juno/u/aadityap/universal_manipulation_interface/data/test/checkpoints/epoch_8450.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cfg = get_cfg(ckpt_path)\n",
    "#dump this to a yaml file\n",
    "OmegaConf.save(d_cfg, 'config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using the CTM base workspace! Ensure that you don't wish to use the normal DP base workspace.\n",
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['base_pose', 'arm_rot_wrt_start', 'gripper_pos', 'arm_pos', 'arm_rot']\n",
      "using obs modality: rgb with keys: ['wrist_image', 'base_image']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/juno/u/aadityap/miniforge3/envs/robodiff-retry/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/juno/u/aadityap/miniforge3/envs/robodiff-retry/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion params: 6.721550e+07\n",
      "Vision params: 2.239418e+07\n",
      "_output_dir\n",
      "global_step\n",
      "epoch\n"
     ]
    }
   ],
   "source": [
    "diffusion_policy = get_policy(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00119794  0.00627107  0.04214258 -0.00265307  0.00286261 -0.00144666\n",
      "  0.96996975  0.00254987 -0.02307275 -0.03843752  0.99904     0.00587935\n",
      "  0.8120817 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_pose': array([-0.00119794,  0.00627107,  0.04214258], dtype=float32),\n",
       " 'arm_pos': array([-0.00265307,  0.00286261, -0.00144666], dtype=float32),\n",
       " 'arm_quat': array([-0.00249938, -0.01189423, -0.00128439,  0.99992531]),\n",
       " 'gripper_pos': array([0.8120817], dtype=float32)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_policy(diffusion_policy, False, diffusion_pw_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACT++ Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'action_dim': 13, 'backbone': 'resnet18', 'frozen_backbone': False, 'dilation': False, 'position_embedding': 'sine', 'camera_names': ['base_image', 'wrist_image'], 'no_encoder': False, 'enc_layers': 4, 'dec_layers': 7, 'dim_feedforward': 2048, 'hidden_dim': 256, 'dropout': 0.1, 'nheads': 8, 'num_queries': 400, 'pre_norm': False, 'vq': False, 'vq_class': 12, 'vq_dim': 64, 'masks': False}\n"
     ]
    }
   ],
   "source": [
    "cfg_path = 'actpp/example_actpp_cfg.yaml'\n",
    "cfg = OmegaConf.load(cfg_path)\n",
    "print(cfg.policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming state dim is 19 because this is the mobile base repo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/juno/u/aadityap/miniforge3/envs/robodiff-retry/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/juno/u/aadityap/miniforge3/envs/robodiff-retry/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use VQ: False, 12, 64\n",
      "Using Camera Names ['base_image', 'wrist_image']\n",
      "number of parameters: 55.23M\n",
      "KL Weight 0.1\n"
     ]
    }
   ],
   "source": [
    "actpp_policy = ACTPolicy(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.291825   -0.72286344  0.05941978  1.4747369   0.5093037  -0.57023007\n",
      " -0.56569695  0.510679   -0.0350954  -0.7592864  -0.5361282   0.08769123\n",
      "  0.37533844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/juno/u/aadityap/universal_manipulation_interface/actpp/models/position_encoding.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n"
     ]
    }
   ],
   "source": [
    "_ = test_policy(actpp_policy, True, actpp_pw_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
